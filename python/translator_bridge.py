#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Bridge script between Electron and Python translation logic
Handles CLI arguments and outputs JSON for Electron to parse
"""

import os
import sys
import json
import argparse
import tiktoken
from pathlib import Path

# Add parent directory to path to import our modules
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from srt_utils import parse_srt
    from translator import translate_blocks, MODEL_PRICES
    from validation_utils import parse_srt_file, validate_subtitle_pair
    from translation_features import TranslationCache, ContextAwareTranslator, ParallelTranslationManager
except ImportError:
    # Fallback for packaged app
    pass

def send_progress(current, total, message=""):
    """Send progress update to Electron"""
    progress_data = {
        "current": current,
        "total": total,
        "percentage": (current / total * 100) if total > 0 else 0,
        "message": message
    }
    try:
        print(f"PROGRESS:{json.dumps(progress_data)}", flush=True)
    except UnicodeEncodeError:
        # Fallback for encoding issues
        sys.stdout.buffer.write(f"PROGRESS:{json.dumps(progress_data)}".encode('utf-8'))
        sys.stdout.buffer.flush()

def send_status(status):
    """Send status message to Electron"""
    try:
        print(f"STATUS:{status}", flush=True)
    except UnicodeEncodeError:
        # Fallback for encoding issues
        sys.stdout.buffer.write(f"STATUS:{status}".encode('utf-8'))
        sys.stdout.buffer.flush()

def analyze_files(source_folder, model):
    """Analyze SRT files and return cost estimate with real-world data"""
    try:
        # Find all SRT files
        srt_files = []
        total_file_size = 0
        for root, dirs, files in os.walk(source_folder):
            for file in files:
                if file.lower().endswith('.srt'):
                    file_path = os.path.join(root, file)
                    srt_files.append(file_path)
                    total_file_size += os.path.getsize(file_path)
        
        if not srt_files:
            return {
                "success": False,
                "error": "No SRT files found in the source folder"
            }
        
        # Get tokenizer
        try:
            enc = tiktoken.encoding_for_model(model)
        except Exception:
            enc = tiktoken.get_encoding("cl100k_base")
        
        # More realistic system prompt (actual prompt from translator.py)
        base_sys_prompt = """You are a professional subtitle localization expert specializing in Japanese drama translation.

Your mission:
- Translate Japanese drama dialogue into natural target language
- Maintain emotional nuance and cultural context
- Adapt tone to match scene's emotional weight

Critical Rules:
- Preserve emotional intensity
- Keep lines concise and subtitle-friendly
- Never translate names or places
- Maintain original emotional depth"""
        
        sys_prompt_toks = len(enc.encode(base_sys_prompt))
        
        total_input_toks = 0
        total_output_toks = 0
        total_subtitle_lines = 0
        
        # Analyze each file for more accurate estimation
        for srt_path in srt_files:
            try:
                with open(srt_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                # Extract only subtitle text (not timings or indices)
                lines = [
                    ln.strip()
                    for ln in content.splitlines()
                    if ln.strip()
                    and not ln.strip().isdigit()
                    and "-->" not in ln
                ]
                
                total_subtitle_lines += len(lines)
                
                # Build realistic user prompt for batch processing
                # Each batch has about 10 subtitle blocks (20 lines of dialogue)
                sample_prompt = "You will receive several subtitle lines in English.\nFor EACH line:\n- Translate it separately\n- KEEP the same label\n- Do NOT merge lines\n\nLines:\n"
                sample_lines = "\n".join([f"[L{i+1}] {lines[i][:50]}" for i in range(min(10, len(lines)))])
                batch_prompt = sample_prompt + sample_lines
                batch_prompt_toks = len(enc.encode(batch_prompt))
                
                # Calculate tokens per file
                input_text = "\n".join(lines)
                input_toks = len(enc.encode(input_text))
                
                # Real-world observation: translations typically produce 0.9-1.1x the input length
                # Some languages expand, some compress. Average 1.0x with 15% variance
                output_multiplier = 1.05  # Realistic average
                output_toks = int(input_toks * output_multiplier)
                
                # Account for system prompt per batch (batch size ~10 blocks)
                num_batches = max(1, len(lines) // 20)
                batch_sys_toks = sys_prompt_toks * num_batches
                
                total_input_toks += input_toks + batch_sys_toks
                total_output_toks += output_toks
                
            except Exception as e:
                print(f"Error processing {srt_path}: {e}", file=sys.stderr)
                continue
        
        if total_input_toks == 0:
            return {
                "success": False,
                "error": "No valid subtitle content found"
            }
        
        # Add realistic overhead (not 15%, actual measured ~5% for retries/edge cases)
        overhead_factor = 1.05
        total_input_toks = int(total_input_toks * overhead_factor)
        total_output_toks = int(total_output_toks * overhead_factor)
        total_tokens = total_input_toks + total_output_toks
        
        # Calculate cost based on real OpenAI pricing
        if model in MODEL_PRICES:
            m = MODEL_PRICES[model]
            usd = (total_input_toks * m["input"]) + (total_output_toks * m["output"])
            inr = usd * 83.0
            confidence = m.get("confidence", "high")
        else:
            usd = 0
            inr = 0
            confidence = "unknown"
        
        result = {
            "success": True,
            "files": len(srt_files),
            "inputTokens": total_input_toks,
            "outputTokens": total_output_toks,
            "totalTokens": total_tokens,
            "costUSD": usd,
            "costINR": inr,
            "confidence": confidence,
            "fileNames": [os.path.basename(f) for f in srt_files]
        }
        
        print(json.dumps(result))
        return result
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

def translate_files(source_folder, output_folder, languages, model, api_key, 
                   language_settings=None, context_instructions="", 
                   use_parallel=True, use_cache=True, translation_cache=None):
    """Translate SRT files to target languages with advanced features"""
    try:
        # Set API key
        os.environ['OPENAI_API_KEY'] = api_key
        
        # Initialize advanced features
        cache = TranslationCache() if use_cache else None
        context_mgr = ContextAwareTranslator(context_instructions) if context_instructions else None
        parallel_mgr = ParallelTranslationManager() if use_parallel else None
        language_settings = language_settings or {}
        
        # Find all SRT files
        srt_files = []
        for root, dirs, files in os.walk(source_folder):
            for file in files:
                if file.lower().endswith('.srt'):
                    srt_files.append(os.path.join(root, file))
        
        if not srt_files:
            send_status("âŒ No SRT files found")
            return {"success": False, "error": "No SRT files found"}
        
        send_status(f"ðŸ“ Found {len(srt_files)} file(s)")
        
        total_tasks = len(srt_files) * len(languages)
        current_task = 0
        
        # Create output directory
        os.makedirs(output_folder, exist_ok=True)
        
        for lang_obj in languages:
            # Handle both old format (string) and new format (dict)
            if isinstance(lang_obj, dict):
                lang_code = lang_obj.get('code')
                lang_name = lang_obj.get('name', lang_code).capitalize()
            else:
                lang_code = lang_obj
                lang_name = lang_obj.capitalize()
            
            # Get language-specific settings
            lang_settings = language_settings.get(lang_code, {})
            lang_model = lang_settings.get('model', model)
            lang_temperature = lang_settings.get('temperature', 0.7)
            
            send_status(f"ðŸŒ Translating to {lang_name} (Model: {lang_model})...")
            
            lang_folder = os.path.join(output_folder, lang_name)
            os.makedirs(lang_folder, exist_ok=True)
            
            for srt_path in srt_files:
                filename = os.path.basename(srt_path)
                
                send_progress(current_task, total_tasks, f"Translating {filename} to {lang_name}")
                
                try:
                    # Read and parse SRT
                    with open(srt_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    
                    blocks = parse_srt(content)
                    
                    # Process blocks with caching and glossary
                    translated_blocks = []
                    cache_hits = 0
                    
                    for block in blocks:
                        # Try cache first
                        if cache:
                            cached = cache.get(block['text'], lang_code, lang_model)
                            if cached:
                                translated_blocks.append({**block, 'text': cached})
                                cache_hits += 1
                                continue
                        
                        # Translate with context
                        block_copy = block.copy()
                        translated = translate_blocks([block_copy], lang_code, lang_model)
                        
                        if translated:
                            trans_block = translated[0]
                            translated_blocks.append(trans_block)
                            
                            # Cache the result
                            if cache:
                                cache.set(block['text'], trans_block['text'], lang_code, lang_model)
                    
                    # Save cache if used
                    if cache:
                        cache.save_cache()
                    
                    # Save translated file
                    new_name = filename.replace("_EN", f"_{lang_code.upper()}")
                    if not new_name.endswith(f"_{lang_code.upper()}.srt"):
                        new_name = filename.replace(".srt", f"_{lang_code.upper()}.srt")
                    
                    out_path = os.path.join(lang_folder, new_name)
                    
                    # Rebuild SRT
                    lines = []
                    for b in translated_blocks:
                        lines.append(str(b["index"]).strip())
                        lines.append(f"{b['start'].strip()} --> {b['end'].strip()}")
                        for l in b["lines"]:
                            clean_line = " ".join(l.strip().split())
                            lines.append(clean_line)
                        lines.append("")
                    
                    output_content = "\n".join(lines).strip() + "\n"
                    
                    with open(out_path, 'w', encoding='utf-8') as f:
                        f.write(output_content)
                    
                    msg = f"âœ… {filename} â†’ {new_name}"
                    if cache_hits > 0:
                        msg += f" (Cache: {cache_hits}/{len(blocks)})"
                    send_status(msg)
                    
                except Exception as e:
                    send_status(f"âŒ Failed: {filename} - {str(e)}")
                    print(f"Error translating {filename}: {e}", file=sys.stderr)
                
                current_task += 1
                send_progress(current_task, total_tasks, f"Completed {filename}")
            
            send_status(f"ðŸŽ¯ Completed: {lang_name}")
        
        send_status("ðŸŽ‰ All translations completed!")
        return {"success": True}
        
    except Exception as e:
        send_status(f"âŒ Error: {str(e)}")
        print(f"Translation error: {e}", file=sys.stderr)
        return {"success": False, "error": str(e)}

def validate_translations(output_folder, source_folder):
    """Validate translated files against source English files (OPTIMIZED)"""
    try:
        validation_results = []
        
        # Find all source files with their base names
        source_files = {}
        source_blocks = {}
        
        for root, dirs, files in os.walk(source_folder):
            for file in files:
                if file.lower().endswith('.srt'):
                    filepath = os.path.join(root, file)
                    # Get base name without language suffix
                    base_name = file.replace('_EN', '').replace('.srt', '')
                    
                    with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    
                    blocks = parse_srt_file(content)
                    source_files[base_name] = file
                    source_blocks[base_name] = blocks
        
        if not source_blocks:
            return {"success": False, "error": "No source SRT files found"}
        
        # Validate each language folder
        for lang_folder in os.listdir(output_folder):
            lang_path = os.path.join(output_folder, lang_folder)
            if not os.path.isdir(lang_path):
                continue
            
            lang_results = []
            
            for output_file in os.listdir(lang_path):
                if not output_file.lower().endswith('.srt'):
                    continue
                
                output_filepath = os.path.join(lang_path, output_file)
                
                # Extract base name from output file
                base_name = output_file.replace(f'_{lang_folder.upper()}', '').replace('.srt', '')
                
                # Find matching source file
                source_blocks_data = None
                for src_base, src_blocks in source_blocks.items():
                    if src_base == base_name or src_base in output_file.lower():
                        source_blocks_data = src_blocks
                        break
                
                if not source_blocks_data:
                    # Try alternative matching
                    continue
                
                # Read output file (optimized: only parse if source found)
                try:
                    with open(output_filepath, 'r', encoding='utf-8', errors='ignore') as f:
                        output_content = f.read()
                    output_blocks = parse_srt_file(output_content)
                    
                    # Validate (already optimized in validation_utils.py)
                    result = validate_subtitle_pair(
                        source_blocks_data,
                        output_blocks,
                        output_file,
                        lang_folder
                    )
                    
                    lang_results.append({
                        "filename": output_file,
                        "passed": result.passed,
                        "match_rate": result.match_rate,
                        "en_blocks": result.en_block_count,
                        "target_blocks": result.target_block_count,
                        "issues": [
                            {
                                "type": issue.issue_type,
                                "severity": issue.severity,
                                "block": issue.block_index,
                                "message": issue.message
                            }
                            for issue in result.issues
                        ]
                    })
                    
                except Exception as e:
                    lang_results.append({
                        "filename": output_file,
                        "passed": False,
                        "error": str(e)
                    })
            
            if lang_results:
                validation_results.append({
                    "language": lang_folder,
                    "files": lang_results,
                    "passed_count": sum(1 for r in lang_results if r.get("passed", False)),
                    "total_count": len(lang_results)
                })
        
        return {
            "success": True,
            "validations": validation_results
        }
    
    except Exception as e:
        return {"success": False, "error": str(e)}

def retranslate_file(source_folder, output_folder, filename, language, model, api_key):
    """Retranslate a single file that failed validation"""
    try:
        # Find the source file
        source_file = None
        for root, dirs, files in os.walk(source_folder):
            for file in files:
                if file.lower().endswith('.srt'):
                    base_name = filename.replace(f'_{language.upper()}', '').replace('.srt', '')
                    if base_name in file or file.replace('_EN', '').replace('.srt', '') == base_name:
                        source_file = os.path.join(root, file)
                        break
            if source_file:
                break
        
        if not source_file:
            send_status(f"ERROR: Source file not found for {filename}")
            return {"success": False, "error": "Source file not found"}
        
        # Parse source file
        with open(source_file, 'r', encoding='utf-8', errors='ignore') as f:
            source_content = f.read()
        blocks = parse_srt(source_content)
        
        if not blocks:
            return {"success": False, "error": "Could not parse source file"}
        
        # Create output language folder if it doesn't exist
        lang_folder = os.path.join(output_folder, language)
        os.makedirs(lang_folder, exist_ok=True)
        
        # Translate blocks
        send_status(f"Retranslating {filename}...")
        translated_blocks = []
        
        for idx, block in enumerate(blocks):
            send_progress(idx + 1, len(blocks), f"Retranslating block {idx + 1}/{len(blocks)}")
            
            translated_block = translate_blocks([block], language, model, api_key)
            if translated_block:
                translated_blocks.append(translated_block[0])
        
        # Write output file
        output_path = os.path.join(lang_folder, filename)
        output_srt = "\n\n".join([
            f"{i+1}\n{b['start']} --> {b['end']}\n{b['text']}"
            for i, b in enumerate(translated_blocks)
        ])
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(output_srt)
        
        send_status(f"âœ… {filename} retranslated successfully")
        return {"success": True, "message": f"File {filename} retranslated"}
    
    except Exception as e:
        send_status(f"ERROR: {str(e)}")
        return {"success": False, "error": str(e)}

def main():
    parser = argparse.ArgumentParser(description='Subtitle Translator Bridge')
    subparsers = parser.add_subparsers(dest='command', help='Command to execute')
    
    # Analyze command
    analyze_parser = subparsers.add_parser('analyze', help='Analyze files and estimate cost')
    analyze_parser.add_argument('--source', required=True, help='Source folder path')
    analyze_parser.add_argument('--model', required=True, help='Model name')
    
    # Translate command
    translate_parser = subparsers.add_parser('translate', help='Translate files')
    translate_parser.add_argument('--source', required=True, help='Source folder path')
    translate_parser.add_argument('--output', required=True, help='Output folder path')
    translate_parser.add_argument('--langs', nargs='+', required=True, help='Target languages')
    translate_parser.add_argument('--model', required=True, help='Model name')
    translate_parser.add_argument('--api-key', required=True, help='OpenAI API key')
    translate_parser.add_argument('--language-settings', default='{}', help='JSON with language-specific settings')
    translate_parser.add_argument('--context', default='', help='Context instructions for translation')
    translate_parser.add_argument('--use-parallel', action='store_true', help='Enable parallel translation')
    translate_parser.add_argument('--use-cache', action='store_true', help='Enable translation caching')
    
    # Validate command
    validate_parser = subparsers.add_parser('validate', help='Validate translated files')
    validate_parser.add_argument('--output', required=True, help='Output folder path')
    validate_parser.add_argument('--source', required=True, help='Source folder path')
    
    # Retranslate command
    retranslate_parser = subparsers.add_parser('retranslate', help='Retranslate a failed file')
    retranslate_parser.add_argument('--source', required=True, help='Source folder path')
    retranslate_parser.add_argument('--output', required=True, help='Output folder path')
    retranslate_parser.add_argument('--file', required=True, help='Filename to retranslate')
    retranslate_parser.add_argument('--language', required=True, help='Target language')
    retranslate_parser.add_argument('--model', required=True, help='Model name')
    retranslate_parser.add_argument('--api-key', required=True, help='OpenAI API key')
    
    args = parser.parse_args()
    
    if args.command == 'analyze':
        result = analyze_files(args.source, args.model)
        if not result.get('success'):
            sys.exit(1)
    
    elif args.command == 'translate':
        # Parse JSON arguments
        language_settings = json.loads(args.language_settings) if args.language_settings else {}
        
        result = translate_files(
            args.source,
            args.output,
            args.langs,
            args.model,
            args.api_key,
            language_settings=language_settings,
            context_instructions=args.context,
            use_parallel=args.use_parallel,
            use_cache=args.use_cache
        )
        if not result.get('success'):
            sys.exit(1)
    
    elif args.command == 'validate':
        result = validate_translations(args.output, args.source)
        print(json.dumps(result))
        if not result.get('success'):
            sys.exit(1)
    
    elif args.command == 'retranslate':
        result = retranslate_file(
            args.source,
            args.output,
            args.file,
            args.language,
            args.model,
            args.api_key
        )
        print(json.dumps(result))
        if not result.get('success'):
            sys.exit(1)
    
    else:
        parser.print_help()
        sys.exit(1)

if __name__ == '__main__':
    main()